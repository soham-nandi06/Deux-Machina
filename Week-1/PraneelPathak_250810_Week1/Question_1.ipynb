{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "8rnSshDrk4ci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lIYdn1woOS1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d924257-7915-4f3f-8b3c-384341dc175f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install gymnasium\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning parameters\n",
        "ALPHA = 0.8        # learning rate (given)\n",
        "GAMMA = 0.95       # discount factor (given)\n",
        "\n",
        "# Epsilon parameters (Exponential Decay)\n",
        "EPS_START = 1.0\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 0.9995  # close to 1\n",
        "\n",
        "EPISODES = 8000\n",
        "MAX_STEPS = 100"
      ],
      "metadata": {
        "id": "YJrV1L4pnNen"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FrozenLake environment\n",
        "env = gym.make(\"FrozenLake-v1\", map_name=\"8x8\", is_slippery=False)\n",
        "\n",
        "\n",
        "state_space = env.observation_space.n\n",
        "action_space = env.action_space.n\n",
        "\n",
        "# Initialize Q-table with all zeros and maintain an list for rewards in all the episodes\n",
        "Q = np.zeros((state_space, action_space))"
      ],
      "metadata": {
        "id": "i7rQrd3tyXfw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "H0fp9ZKn2uQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(EPISODES):\n",
        "    # Start the episode\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    # Calculate epsilon for this episode\n",
        "    epsilon = max(EPS_END, EPS_START * (EPS_DECAY ** episode))\n",
        "\n",
        "    for step in range(MAX_STEPS):\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()   # Exploration\n",
        "        else:\n",
        "            action = np.argmax(Q[state])         # Exploitation\n",
        "\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # A penalty is required for falling into hole. Otherwise, agent will never learn(Q-table will have all zeros)\n",
        "        if reward == 0 and done:\n",
        "            reward = -0.01\n",
        "\n",
        "        # Temporal Difference error\n",
        "        td_error = reward + GAMMA * np.max(Q[next_state]) - Q[state, action]\n",
        "\n",
        "        # Q-value update\n",
        "        Q[state, action] += ALPHA * td_error\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    rewards_all_episodes.append(total_reward)\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KZ5b8Nc-nvVn",
        "outputId": "3cb94650-53d5-4348-ce49-fbb9edc2b249"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Q-table"
      ],
      "metadata": {
        "id": "2uVbgo5a2yTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"frozenlake_qtable.npy\", Q)\n",
        "\n",
        "Q = np.load(\"frozenlake_qtable.npy\")"
      ],
      "metadata": {
        "id": "XvCWgY2RpFhv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "0owTUVKr23h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_episodes = 100\n",
        "successes = 0\n",
        "\n",
        "for episode in range(test_episodes):\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "\n",
        "    for step in range(MAX_STEPS):\n",
        "        action = np.argmax(Q[state])  # purely greedy\n",
        "        state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if done:\n",
        "            if reward == 1:\n",
        "                successes += 1\n",
        "            break\n",
        "\n",
        "print(f\"Success rate: {successes}/{test_episodes}\")\n",
        "# Note- A 100% success rate is seen because agent takes best action at all points and is_slippery was set to False.\n",
        "#       So there is no randomness and the agent takes same path in every test episode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpMvE4L-pRHX",
        "outputId": "df1c99bc-5d26-4918-bc3f-72dcd6fd8b96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 100/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Visualisation"
      ],
      "metadata": {
        "id": "lu-CKMRc2HC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Visualisation\n",
        "print(\"State space:\", state_space)\n",
        "print(\"Action space:\", action_space)\n",
        "print(\"Environment:\")\n",
        "desc = env.unwrapped.desc\n",
        "for row in desc:\n",
        "    print(\"\\t\", \" \".join(cell.decode(\"utf-8\") for cell in row))\n",
        "print(\"\\nKey: \\tS -> Start\\n\\tF -> Frozen\\n\\tH -> Hole\\n\\tG -> Goal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atXqQZhf2FU4",
        "outputId": "9874d0c8-3014-4750-d6d7-13c9b0d206d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State space: 64\n",
            "Action space: 4\n",
            "Environment:\n",
            "\t S F F F F F F F\n",
            "\t F F F F F F F F\n",
            "\t F F F H F F F F\n",
            "\t F F F F F H F F\n",
            "\t F F F H F F F F\n",
            "\t F H H F F F H F\n",
            "\t F H F F H F H F\n",
            "\t F F F H F F F G\n",
            "\n",
            "Key: \tS -> Start\n",
            "\tF -> Frozen\n",
            "\tH -> Hole\n",
            "\tG -> Goal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Policy Visualisation\n",
        "actions = [\"←\", \"↓\", \"→\", \"↑\"]\n",
        "\n",
        "policy = np.array([actions[np.argmax(Q[state])] for state in range(state_space)])\n",
        "policy = policy.reshape((8, 8))\n",
        "\n",
        "print(\"Optimal Policy:\")\n",
        "for row in policy:\n",
        "    print(\"\\t\",\" \".join(cell for cell in row))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w-mnm62pWev",
        "outputId": "5e334b39-0b49-4599-c532-914f1d11809d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy:\n",
            "\t ↓ ↓ ← ← ← ← ← ←\n",
            "\t ↓ ↓ ← ← ← ↓ ← ←\n",
            "\t ↓ ↓ ↓ ← ↓ ← ← ←\n",
            "\t → → → → ↓ ← ↓ ↓\n",
            "\t ↑ ← ↑ ← → → → ↓\n",
            "\t ← ← ← → ↑ ↑ ← ↓\n",
            "\t ↓ ← ↓ ← ← ↓ ← ↓\n",
            "\t → ← ← ← → ← ← ←\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Q-table\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "for state in range(Q.shape[0]):\n",
        "    print(f\"State {state}: {Q[state]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kmuPc-yqNzn",
        "outputId": "026c3ea1-6c6c-4836-c1c7-49cba8310aa6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State 0: [0.488 0.513 0.513 0.488]\n",
            "State 1: [0.488 0.54  0.488 0.513]\n",
            "State 2: [0.513 0.    0.    0.39 ]\n",
            "State 3: [0.39 0.   0.   0.  ]\n",
            "State 4: [0. 0. 0. 0.]\n",
            "State 5: [ 0.  0. -0.  0.]\n",
            "State 6: [ 0.  0. -0.  0.]\n",
            "State 7: [ 0. -0.  0.  0.]\n",
            "State 8: [0.513 0.54  0.54  0.488]\n",
            "State 9: [0.513 0.569 0.513 0.513]\n",
            "State 10: [0.54  0.    0.462 0.468]\n",
            "State 11: [ 0.513 -0.01   0.     0.   ]\n",
            "State 12: [0.452 0.    0.    0.   ]\n",
            "State 13: [-0.  0.  0.  0.]\n",
            "State 14: [0. 0. 0. 0.]\n",
            "State 15: [ 0.  0. -0. -0.]\n",
            "State 16: [0.54  0.569 0.569 0.513]\n",
            "State 17: [0.54  0.599 0.599 0.54 ]\n",
            "State 18: [ 0.569  0.63  -0.01   0.509]\n",
            "State 19: [0. 0. 0. 0.]\n",
            "State 20: [-0.01   0.698  0.     0.237]\n",
            "State 21: [ 0.635 -0.01   0.     0.   ]\n",
            "State 22: [0.563 0.    0.    0.   ]\n",
            "State 23: [0.304 0.    0.    0.   ]\n",
            "State 24: [0.569 0.54  0.599 0.54 ]\n",
            "State 25: [0.569 0.513 0.63  0.569]\n",
            "State 26: [0.599 0.599 0.663 0.599]\n",
            "State 27: [ 0.63  -0.01   0.698 -0.01 ]\n",
            "State 28: [ 0.663  0.735 -0.01   0.663]\n",
            "State 29: [0. 0. 0. 0.]\n",
            "State 30: [-0.01   0.815  0.803  0.   ]\n",
            "State 31: [0.762 0.857 0.781 0.   ]\n",
            "State 32: [ 0.389 -0.002  0.4    0.569]\n",
            "State 33: [ 0.54  -0.01   0.479  0.477]\n",
            "State 34: [-0.   -0.01 -0.01  0.63]\n",
            "State 35: [0. 0. 0. 0.]\n",
            "State 36: [-0.01   0.698  0.774  0.698]\n",
            "State 37: [ 0.735  0.735  0.815 -0.01 ]\n",
            "State 38: [ 0.774 -0.01   0.857  0.774]\n",
            "State 39: [0.815 0.902 0.857 0.815]\n",
            "State 40: [-0.   -0.   -0.01 -0.  ]\n",
            "State 41: [0. 0. 0. 0.]\n",
            "State 42: [0. 0. 0. 0.]\n",
            "State 43: [-0.01  -0.     0.697 -0.01 ]\n",
            "State 44: [ 0.645 -0.01  -0.     0.735]\n",
            "State 45: [ 0.698  0.    -0.01   0.774]\n",
            "State 46: [0. 0. 0. 0.]\n",
            "State 47: [-0.01   0.95   0.902  0.857]\n",
            "State 48: [-0.008 -0.    -0.01  -0.   ]\n",
            "State 49: [0. 0. 0. 0.]\n",
            "State 50: [-0.01  -0.    -0.001 -0.01 ]\n",
            "State 51: [-0.    -0.01  -0.01  -0.008]\n",
            "State 52: [0. 0. 0. 0.]\n",
            "State 53: [-0.01  0.    0.    0.  ]\n",
            "State 54: [0. 0. 0. 0.]\n",
            "State 55: [-0.01   1.     0.95   0.902]\n",
            "State 56: [-0. -0. -0. -0.]\n",
            "State 57: [-0.   -0.   -0.   -0.01]\n",
            "State 58: [-0.   -0.   -0.01 -0.  ]\n",
            "State 59: [0. 0. 0. 0.]\n",
            "State 60: [-0.01  -0.002  0.    -0.01 ]\n",
            "State 61: [0. 0. 0. 0.]\n",
            "State 62: [0. 0. 0. 0.]\n",
            "State 63: [0. 0. 0. 0.]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}