{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20b8d68",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62441e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cbe5a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Q table: [[ 1.73087527  1.1134803   0.76905258 -0.27245608]\n",
      " [-0.16015009  0.78864344 -0.20740835 -1.31232541]\n",
      " [ 0.54777602  0.71036199  1.93092591  1.63196934]\n",
      " [ 0.22362559  0.93106984 -2.18750291 -0.78349026]\n",
      " [-0.94251364  0.559862   -0.1445933   1.80095235]\n",
      " [-1.16240211  1.73046564  0.10144775 -1.2242588 ]\n",
      " [ 0.4949491  -1.50333057  1.55972992  2.397711  ]\n",
      " [-0.93242636 -0.58221982 -0.46783698 -0.59821223]\n",
      " [-0.06934199 -1.14026275  0.11596209  0.34536699]\n",
      " [ 0.13533587  0.61510364 -1.40728686  2.3032154 ]\n",
      " [-1.83891698  0.25674212 -0.43181042  1.14431698]\n",
      " [ 1.17882461 -0.03382959  1.28403042  0.52752311]\n",
      " [ 0.58821213  0.03364813  1.20812984 -1.03461862]\n",
      " [ 0.33463111 -0.41578877 -0.33699471  0.07411752]\n",
      " [ 0.62614173 -1.06670212 -1.17428194 -1.35778512]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "Final Q table: [[ 7.35091891  7.73780937  7.73780937  7.35091891]\n",
      " [ 7.35091891 -3.35605764  8.1450625   7.73780937]\n",
      " [ 7.73780937  8.57375     7.73780937  8.1450625 ]\n",
      " [ 8.1450625  -5.44444513  7.73780933  7.73780937]\n",
      " [ 7.73780937  8.1450625  -3.35605764  7.35091891]\n",
      " [-1.16240211  1.73046564  0.10144775 -1.2242588 ]\n",
      " [-3.35605764  9.025      -5.44444513  8.1450625 ]\n",
      " [-0.93242636 -0.58221982 -0.46783698 -0.59821223]\n",
      " [ 8.1450625  -3.85227665  8.57375     7.73780937]\n",
      " [ 8.1450625   9.025       9.025      -3.35605764]\n",
      " [ 8.57375     9.5        -3.7801711   8.57375   ]\n",
      " [ 1.17882461 -0.03382959  1.28403042  0.52752311]\n",
      " [ 0.58821213  0.03364813  1.20812984 -1.03461862]\n",
      " [-3.85227665  9.025       9.5         8.57375   ]\n",
      " [ 9.025       9.5        10.          9.025     ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "a=0.8 #learning rate\n",
    "g=0.95 #discount factor\n",
    "\n",
    "rng=np.random.default_rng() #random number generator\n",
    "\n",
    "env=gym.make(\n",
    "    'FrozenLake-v1',\n",
    "    desc=None,\n",
    "    map_name=\"4x4\",\n",
    "    is_slippery=False,\n",
    "    reward_schedule=(10,-5,0),\n",
    ")\n",
    "\n",
    "def select_action(Q,S,e):\n",
    "    x=rng.random()\n",
    "    if x<e:\n",
    "        return rng.integers(low=0,high=4)\n",
    "    else:\n",
    "        return Q[S].argmax()\n",
    "\n",
    "Q=np.random.randn(64).reshape((16,4)) #make a arbitrary Q table and store it as a 16x4 array\n",
    "Q[15]=[0,0,0,0]\n",
    "print(\"Initial Q table:\",Q)\n",
    "\n",
    "state,info=env.reset()\n",
    "run=True\n",
    "n=0\n",
    "\n",
    "while n<10000:\n",
    "    while run:\n",
    "        e=max(0.01,0.999**n) # eps_start=1, eps_end=0.01, eps_decay=0.999, epsilon = max(eps_end, eps_start*(eps_decay)**(episode_number))\n",
    "        action = select_action(Q,state,e)\n",
    "        prev_state=state\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        q=Q[state].max()\n",
    "        Q[prev_state][action]+=a*(reward+g*q-Q[prev_state][action]) # Q learning implementation\n",
    "\n",
    "        if truncated or terminated:\n",
    "            state, info=env.reset()\n",
    "            run=False\n",
    "    n+=1\n",
    "    run=True\n",
    "\n",
    "print(\"Final Q table:\",(Q))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e71ace",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c022f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "env1=gym.make(\n",
    "    'FrozenLake-v1',\n",
    "    desc=None,\n",
    "    map_name=\"4x4\",\n",
    "    is_slippery=False,\n",
    "    reward_schedule=(10, -5, 0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "run=True\n",
    "state, info=env1.reset()\n",
    "while run:\n",
    "    action =  Q[state].argmax()\n",
    "    state, reward, terminated, truncated, info = env1.step(action)\n",
    "\n",
    "    if truncated or terminated:\n",
    "        state, info=env1.reset()\n",
    "        run=False\n",
    "env1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
